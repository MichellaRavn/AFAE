{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Fairness, Accountability, and Ethics, Spring 2025\n",
    "\n",
    "## Mandatory Assignment 2\n",
    "\n",
    "Please use the following code to prepare the dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_14220\\1932773561.py:55: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['SCHL'].replace({17.0:16.0, 18.0:17.0, 19.0:18.0, 20.0:19.0, 21.0:20.0, 22.0:21.0, 23.0:21.0, 24.0:22.0}, inplace=True)\n",
      "C:\\Users\\Bruger\\AppData\\Local\\Temp\\ipykernel_14220\\1932773561.py:58: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"MAR\"].replace({3:2, 4:2, 5:2}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from folktables.acs import adult_filter\n",
    "from folktables import ACSDataSource\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.optimize import fmin_tnc\n",
    "import pandas as pd\n",
    "\n",
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=False)\n",
    "\n",
    "feature_names = ['AGEP', # Age\n",
    "                 \"CIT\", # Citizenship status\n",
    "                 'COW', # Class of worker\n",
    "                 \"ENG\", # Ability to speak English\n",
    "                 'SCHL', # Educational attainment\n",
    "                 'MAR', # Marital status\n",
    "                 \"HINS1\", # Insurance through a current or former employer or union\n",
    "                 \"HINS2\", # Insurance purchased directly from an insurance company\n",
    "                 \"HINS4\", # Medicaid\n",
    "                 \"RAC1P\", # Recoded detailed race code\n",
    "                 'SEX', # Binary value for sex\n",
    "                 \"DIS\", # Binary value for disability\n",
    "                 \"VPS\"] # Binary value for veteran status\n",
    "\n",
    "target_name = \"PINCP\" # Total person's income\n",
    "\n",
    "def data_processing(data, features, target_name:str, threshold: float = 35000):\n",
    "    df = data\n",
    "    ### Adult Filter (STARTS) (from Foltktables)\n",
    "    df = df[~df[\"SEX\"].isnull()]\n",
    "    df = df[~df[\"RAC1P\"].isnull()]\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    ### Adult Filter (ENDS)\n",
    "    ### Groups of interest\n",
    "    # SEX\n",
    "    sex = df[\"SEX\"].values\n",
    "    # DISABILITY\n",
    "    dis = df[\"DIS\"].values-1\n",
    "    # RACE\n",
    "    race = np.zeros((np.shape(df[\"SEX\"])))\n",
    "    race[df[\"RAC1P\"]==2]=1\n",
    "    race[df[\"RAC1P\"]==1]=2\n",
    "    # VETERAN\n",
    "    df[\"VPS\"]=-(df[\"VPS\"].notnull().astype(int)-1)\n",
    "    df[\"VPS\"]=df[\"VPS\"].fillna(0)\n",
    "    vps = df[\"VPS\"].values\n",
    "    # SCHL data grouping \n",
    "    # grouping 16+17 and 22+23\n",
    "    df['SCHL'].replace({17.0:16.0, 18.0:17.0, 19.0:18.0, 20.0:19.0, 21.0:20.0, 22.0:21.0, 23.0:21.0, 24.0:22.0}, inplace=True)\n",
    "    # MAR data grouping\n",
    "    # Grouping the not married categories\n",
    "    df[\"MAR\"].replace({3:2, 4:2, 5:2}, inplace=True)\n",
    "    ### Target\n",
    "    df[\"target\"] = df[target_name] > threshold\n",
    "    target = df[\"target\"].values\n",
    "    df = df[features + [\"target\", target_name]] ##we want to keep df before one_hot encoding to make Bias Analysis\n",
    "    df_processed = df[features].copy()\n",
    "    cols = [ \"HINS1\", \"HINS2\", \"HINS4\", \"CIT\", \"COW\", \"MAR\", \"SEX\", \"RAC1P\", \"DIS\", \"VPS\"]\n",
    "    df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=False, columns=cols, drop_first=True)\n",
    "    # For one-hot-encoding english abilities, which we decided not to do\n",
    "    #df_processed = pd.get_dummies(df_processed, prefix=None, prefix_sep='_', dummy_na=True, columns=[\"ENG\"], drop_first=True)\n",
    "    # Adding an intercept column, for fitting log reg\n",
    "    df_processed['Intercept']=1\n",
    "    # Reorder the columns so that 'x0' becomes the first column\n",
    "    df_processed = df_processed[['Intercept'] + [col for col in df_processed.columns if col != 'Intercept']]\n",
    "\n",
    "    return df_processed, df, target, sex, race, dis, vps\n",
    "\n",
    "data, data_original, target, groupsex, grouprace, _, _ = data_processing(acs_data, feature_names, target_name)\n",
    "\n",
    "# Standardizing since we are fitting a logistic regression model \n",
    "# School\n",
    "scaler=MinMaxScaler()\n",
    "data[\"SCHL\"]=scaler.fit_transform(data[[\"SCHL\"]])\n",
    "\n",
    "# Age\n",
    "scaler=MinMaxScaler()\n",
    "data[\"AGEP\"]=scaler.fit_transform(data[[\"AGEP\"]]).astype(float)\n",
    "\n",
    "# English abilities\n",
    "# Filling nan values with zero\n",
    "data[\"ENG\"]=data[\"ENG\"].fillna(0)\n",
    "\n",
    "# Flipping the data such that 0 is no english ability and 4 is native/professional\n",
    "data[\"ENG\"]=-(data[\"ENG\"]-4)\n",
    "scaler=MinMaxScaler()\n",
    "data[\"ENG\"]=scaler.fit_transform(data[[\"ENG\"]]).astype(float)\n",
    "\n",
    "# Splitting in a training and test set\n",
    "X_train, X_test, y_train, y_test, groupsex_train, groupsex_test, grouprace_train, grouprace_test = train_test_split(\n",
    "    data, target, groupsex, grouprace, test_size=0.2, random_state=0)\n",
    "\n",
    "# Ensuring entries are floats for later numpy operations\n",
    "X_train=X_train.astype(float)\n",
    "y_train=y_train.astype(float)\n",
    "X_test=X_test.astype(float)\n",
    "y_test=y_test.astype(float)\n",
    "#X_train = X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Intercept', 'AGEP', 'ENG', 'SCHL', 'HINS1_2', 'HINS2_2', 'HINS4_2',\n",
       "       'CIT_2', 'CIT_3', 'CIT_4', 'CIT_5', 'COW_2.0', 'COW_3.0', 'COW_4.0',\n",
       "       'COW_5.0', 'COW_6.0', 'COW_7.0', 'COW_8.0', 'MAR_2', 'SEX_2', 'RAC1P_2',\n",
       "       'RAC1P_3', 'RAC1P_4', 'RAC1P_5', 'RAC1P_6', 'RAC1P_7', 'RAC1P_8',\n",
       "       'RAC1P_9', 'DIS_2', 'VPS_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n",
    "# We should consider grouping working class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model without any fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is: 0.7622211432806072\n",
      "the group accuracy is:\n",
      " Male      0.780467\n",
      "Female    0.741897\n",
      "Name: Group Accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(beta, X):\n",
    "    return 1/(1+np.exp(-(X @ beta)))\n",
    "\n",
    "# Logistic loss \n",
    "def logistic_loss(beta, X, y, lambda_, gamma_):\n",
    "    m = len(y)\n",
    "    g = sigmoid(beta, X)\n",
    "    return 1/m* np.sum(-y * np.log(g) - (1-y) * np.log(1-g))\n",
    "\n",
    "# Objective function to minimize\n",
    "def objective_function(beta, X, y, lambda_, gamma_):\n",
    "    lloss=logistic_loss(beta, X, y, lambda_,gamma_)\n",
    "    f=0 # not including any fairness constraint yet\n",
    "    l2loss=np.sum(beta**2)\n",
    "    return lloss+gamma_*l2loss+lambda_*f\n",
    "\n",
    "# Function for the given f prime\n",
    "def fprime(beta, X, y, lambda_, gamma_):\n",
    "    m = len(y)\n",
    "    g = sigmoid(beta, X)\n",
    "    return 1/m * np.dot(X.T,(g-y))+2*gamma_*beta\n",
    "\n",
    "# The given evaluation error function\n",
    "def evaluate_error(y_pred,labels_, group_):\n",
    "    # amount of groups\n",
    "    unique_groups = np.unique(group_)\n",
    "\n",
    "    group_accuracy={g: np.nan for g in group_}\n",
    "\n",
    "    for g in unique_groups:\n",
    "        idx=group_==g\n",
    "        group_accuracym=accuracy_score(y_pred[idx], labels_[idx])\n",
    "        group_accuracy[g]=group_accuracym\n",
    "    \n",
    "    group_accuracy_df = pd.Series({int(k): float(v) for k, v in group_accuracy.items()}, name=\"Group Accuracy\")\n",
    "    \n",
    "    overallaccuracy = accuracy_score(y_pred, labels_)\n",
    "    \n",
    "    return y_pred, overallaccuracy, group_accuracy_df\n",
    "\n",
    "# Initial values\n",
    "beta0 = np.zeros(X_train.shape[1])\n",
    "lambda1=1\n",
    "gamma1=1e-5\n",
    "\n",
    "\n",
    "optimal_beta, nfeval, rc = fmin_tnc(func=objective_function,x0=beta0,fprime=fprime, args=(X_train,y_train, lambda1, gamma1), ftol=1e-5)\n",
    "#print(\"Optimized beta:\", optimal_beta)\n",
    "\n",
    "\n",
    "y_pred_fair = np.array([True if x >=0.5 else False for x in sigmoid(optimal_beta, X_test)])\n",
    "\n",
    "\n",
    "\n",
    "predictions, accuracy, group_acc = evaluate_error(y_pred_fair, y_test, groupsex_test)\n",
    "\n",
    "# Group labels\n",
    "group_labels = {1: \"Male\", 2: \"Female\"}\n",
    "\n",
    "# Convert numeric keys to labels\n",
    "group_acc = {group_labels.get(k, f\"Unknown {k}\"): v for k, v in group_acc.items()}\n",
    "\n",
    "# Convert to pandas Series\n",
    "group_acc_df = pd.Series(group_acc, name=\"Group Accuracy\")\n",
    "\n",
    "\n",
    "print(\"the accuracy is:\", accuracy)\n",
    "print(\"the group accuracy is:\\n\", group_acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated betas:\n",
      "      features    weight\n",
      "0   Intercept -4.476678\n",
      "1        AGEP  3.491834\n",
      "2         ENG  0.886671\n",
      "3        SCHL  3.619274\n",
      "4     HINS1_2 -1.065311\n",
      "5     HINS2_2 -0.154251\n",
      "6     HINS4_2  0.836031\n",
      "7       CIT_2 -0.074670\n",
      "8       CIT_3  0.061906\n",
      "9       CIT_4  0.170950\n",
      "10      CIT_5  0.031584\n",
      "11    COW_2.0  0.099171\n",
      "12    COW_3.0  0.151214\n",
      "13    COW_4.0  0.190287\n",
      "14    COW_5.0  0.568497\n",
      "15    COW_6.0 -0.557678\n",
      "16    COW_7.0  0.337733\n",
      "17    COW_8.0 -1.082878\n",
      "18      MAR_2 -0.499185\n",
      "19      SEX_2 -0.730500\n",
      "20    RAC1P_2 -0.309954\n",
      "21    RAC1P_3 -0.208853\n",
      "22    RAC1P_4 -0.011931\n",
      "23    RAC1P_5 -0.265389\n",
      "24    RAC1P_6  0.050249\n",
      "25    RAC1P_7 -0.162122\n",
      "26    RAC1P_8 -0.092507\n",
      "27    RAC1P_9 -0.115835\n",
      "28      DIS_2  0.403215\n",
      "29      VPS_1 -0.112106\n"
     ]
    }
   ],
   "source": [
    "betas={'features': X_test.columns.tolist(), 'weight':optimal_beta}\n",
    "df = pd.DataFrame(data=betas)\n",
    "print(\"Estimated betas:\\n\" ,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized beta: [-4.47667843  3.49183449  0.88667076  3.61927419 -1.06531136 -0.15425147\n",
      "  0.83603108 -0.07467042  0.06190613  0.1709502   0.03158363  0.09917071\n",
      "  0.15121407  0.19028749  0.56849651 -0.55767793  0.33773279 -1.08287766\n",
      " -0.4991854  -0.73049998 -0.3099535  -0.20885309 -0.0119313  -0.26538944\n",
      "  0.05024909 -0.1621224  -0.09250687 -0.11583547  0.40321546 -0.11210612]\n",
      "the accuracy is: 0.7622211432806072\n",
      "the group accuracy is:\n",
      " Black or African American alone    0.766996\n",
      "Unknown 0                          0.756761\n",
      "White alone                        0.736749\n",
      "Name: Group Accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "optimal_beta, nfeval, rc = fmin_tnc(func=objective_function,x0=beta0,fprime=fprime, args=(X_train,y_train, lambda1, gamma1), ftol=1e-5)\n",
    "print(\"Optimized beta:\", optimal_beta)\n",
    "y_pred_fair = np.array([True if x >=0.5 else False for x in sigmoid(optimal_beta, X_test)])\n",
    "\n",
    "\n",
    "predictions, accuracy, group_acc = evaluate_error(y_pred_fair, y_test, grouprace_test)\n",
    "\n",
    "# Group labels\n",
    "group_labels = {1: \"White alone\", 2: \"Black or African American alone\", 3: \"American Indian alone\", 4: \"Alaska Native alone\", 5: \"AI and AN tribes or AI or AN, not specified and no other races\", \n",
    "                6: \"Asian alone\", 7: \"Native Hawaiian and Other Pacific Islander alone\", 8: \"Some Other Race alone\", 9: \"Two or More Races\"}\n",
    "\n",
    "\n",
    "# Convert numeric keys to labels\n",
    "group_acc = {group_labels.get(k, f\"Unknown {k}\"): v for k, v in group_acc.items()}\n",
    "\n",
    "# Convert to pandas Series\n",
    "group_acc_df = pd.Series(group_acc, name=\"Group Accuracy\")\n",
    "\n",
    "\n",
    "print(\"the accuracy is:\", accuracy)\n",
    "print(\"the group accuracy is:\\n\", group_acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated betas:\n",
      "      features    weight\n",
      "0   Intercept -4.476678\n",
      "1        AGEP  3.491834\n",
      "2         ENG  0.886671\n",
      "3        SCHL  3.619274\n",
      "4     HINS1_2 -1.065311\n",
      "5     HINS2_2 -0.154251\n",
      "6     HINS4_2  0.836031\n",
      "7       CIT_2 -0.074670\n",
      "8       CIT_3  0.061906\n",
      "9       CIT_4  0.170950\n",
      "10      CIT_5  0.031584\n",
      "11    COW_2.0  0.099171\n",
      "12    COW_3.0  0.151214\n",
      "13    COW_4.0  0.190287\n",
      "14    COW_5.0  0.568497\n",
      "15    COW_6.0 -0.557678\n",
      "16    COW_7.0  0.337733\n",
      "17    COW_8.0 -1.082878\n",
      "18      MAR_2 -0.499185\n",
      "19      SEX_2 -0.730500\n",
      "20    RAC1P_2 -0.309954\n",
      "21    RAC1P_3 -0.208853\n",
      "22    RAC1P_4 -0.011931\n",
      "23    RAC1P_5 -0.265389\n",
      "24    RAC1P_6  0.050249\n",
      "25    RAC1P_7 -0.162122\n",
      "26    RAC1P_8 -0.092507\n",
      "27    RAC1P_9 -0.115835\n",
      "28      DIS_2  0.403215\n",
      "29      VPS_1 -0.112106\n"
     ]
    }
   ],
   "source": [
    "betas={'features': X_test.columns.tolist(), 'weight':optimal_beta}\n",
    "df = pd.DataFrame(data=betas)\n",
    "print(\"Estimated betas:\\n\" ,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model group fairness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance function discrete\n",
    "def d(y_i, y_j):\n",
    "    return 1 if y_i != y_j else 0\n",
    "\n",
    "# Group fairness function\n",
    "def individual_fairness(beta, X, y, group):\n",
    "    n1=np.sum(group==1)\n",
    "    n2=np.sum(group==2)\n",
    "    # The predictions\n",
    "    pred1 = X[group==1] @ beta\n",
    "    pred2 = X[group==2] @ beta\n",
    "    # The target\n",
    "    y1 = y[group==1]\n",
    "    y2 = y[group==2]\n",
    "\n",
    "    # Allocate space\n",
    "    fairness_loss=0\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            d_ij = d(y1[i], y2[j]) # distance\n",
    "            fairness_loss += d_ij * (pred1[i] - pred2[j]) ** 2\n",
    "    fairness_loss /= n1*n2\n",
    "    return fairness_loss\n",
    "\n",
    "def group_fairness(beta, X, y, group):\n",
    "    n1=np.sum(group==1)\n",
    "    n2=np.sum(group==2)\n",
    "    # The predictions\n",
    "    #X = X.to_numpy()\n",
    "    y_pred = np.array([True if x >=0.5 else False for x in sigmoid(beta, X)])\n",
    "    \n",
    "    # Allocate space\n",
    "    fairness_loss=0\n",
    "\n",
    "    # We want to create a distance matrix\n",
    "    i, j = np.triu_indices(len(y), k=1)  # Get only (i, j) where i < j\n",
    "    equal_mask = y[i] == y[j]\n",
    "    equal_pairs = np.column_stack((i[equal_mask], j[equal_mask]))\n",
    "    \n",
    "    diff_groups = (group[equal_pairs[:,0]] != group[equal_pairs[:,1]]).astype(int)\n",
    "    \n",
    "\n",
    "    # Alternative code, this doesn't account for i<j\n",
    "    #equal_pairs = np.argwhere(y[np.newaxis, :] == y[:, np.newaxis])\n",
    "    #equal_pairs = equal_pairs[np.where(equal_pairs[:,0] != equal_pairs[:,1])]\n",
    "    \n",
    "    # Find pairs where groups are different\n",
    "    #diff_groups = (group[equal_pairs[:,0]] != group[equal_pairs[:,1]]).astype(int)\n",
    "    \n",
    "    \n",
    "\n",
    "    fairness_loss = diff_groups.dot((y_pred[equal_pairs[:,0]] != y_pred[equal_pairs[:,1]])**2)\n",
    "\n",
    "\n",
    "    #for i in range(n1):\n",
    "    #    for j in range(n2):\n",
    "    #        d_ij = d(y1[i], y2[j]) # distance\n",
    "    #        fairness_loss += d_ij * (pred1[i] - pred2[j]) \n",
    "    fairness_loss /= (n1*n2)\n",
    "    return (fairness_loss)**2\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(beta, X):\n",
    "    return 1/(1+np.exp(-(X @ beta)))\n",
    "\n",
    "# Logistic loss\n",
    "def logistic_loss(beta, X, y, lambda_, gamma_):\n",
    "    m = len(y)\n",
    "    g = sigmoid(beta, X)\n",
    "    return 1/m* np.sum(-y * np.log(g) - (1-y) * np.log(1-g))\n",
    "\n",
    "# Objective function\n",
    "def objective_function(beta, X, y, lambda_, gamma_, group):\n",
    "    lloss=logistic_loss(beta, X, y, lambda_,gamma_)\n",
    "    f=group_fairness(beta, X, y, group) # can be changed with individual fairness\n",
    "    l2loss=gamma_*np.sum(beta**2)\n",
    "    return lloss+lambda_*f+l2loss\n",
    "\n",
    "# Given f prime\n",
    "def fprime(beta, X, y, lambda_, gamma_, group):\n",
    "    m = len(y)\n",
    "    g = sigmoid(beta, X)\n",
    "    return 1/m * np.dot(X.T,(g-y))+2*gamma_*beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is: 0.757468121534255\n",
      "the group accuracy is:\n",
      " Male      0.773483\n",
      "Female    0.739628\n",
      "Name: Group Accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Testing for the ACS dataset\n",
    "\n",
    "# I am subsampling because of runtime\n",
    "N = 1000 ##\n",
    "X_train = X_train[:N]\n",
    "y_train = y_train[:N]\n",
    "groupsex_train = groupsex_train [:N]\n",
    "\n",
    "\n",
    "# Initial values\n",
    "beta0 = np.zeros(X_train.shape[1])\n",
    "lambda1=1e-1\n",
    "gamma1=1e-5\n",
    "\n",
    "\n",
    "optimal_beta, nfeval, rc = fmin_tnc(func=objective_function,x0=beta0,fprime=fprime, args=(X_train,y_train, lambda1, gamma1, groupsex_train), ftol=1e-5)\n",
    "#print(\"Optimized beta:\", optimal_beta)\n",
    "\n",
    "\n",
    "y_pred_fair = np.array([True if x >=0.5 else False for x in sigmoid(optimal_beta, X_test)])\n",
    "\n",
    "predictions, accuracy, group_acc = evaluate_error(y_pred_fair, y_test, groupsex_test)\n",
    "\n",
    "# Group labels\n",
    "group_labels = {1: \"Male\", 2: \"Female\"}\n",
    "\n",
    "# Convert numeric keys to labels\n",
    "group_acc = {group_labels.get(k, f\"Unknown {k}\"): v for k, v in group_acc.items()}\n",
    "\n",
    "# Convert to pandas Series\n",
    "group_acc_df = pd.Series(group_acc, name=\"Group Accuracy\")\n",
    "\n",
    "\n",
    "print(\"the accuracy is:\", accuracy)\n",
    "print(\"the group accuracy is:\\n\", group_acc_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is: 0.7580047530217463\n",
      "the group accuracy is:\n",
      " White              0.761871\n",
      "All other races    0.754797\n",
      "Black              0.727915\n",
      "Name: Group Accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## Testing for the ACS dataset\n",
    "\n",
    "# I am subsampling because of runtime\n",
    "N = 1000 ##\n",
    "X_train = X_train[:N]\n",
    "y_train = y_train[:N]\n",
    "grouprace_train = grouprace_train [:N]\n",
    "\n",
    "\n",
    "# Initial values\n",
    "beta0 = np.zeros(X_train.shape[1])\n",
    "lambda1=1e-2\n",
    "gamma1=1e-5\n",
    "\n",
    "\n",
    "optimal_beta, nfeval, rc = fmin_tnc(func=objective_function,x0=beta0,fprime=fprime, args=(X_train,y_train, lambda1, gamma1, grouprace_train), ftol=1e-5)\n",
    "#print(\"Optimized beta:\", optimal_beta)\n",
    "\n",
    "\n",
    "y_pred_fair = np.array([True if x >=0.5 else False for x in sigmoid(optimal_beta, X_test)])\n",
    "\n",
    "predictions, accuracy, group_acc = evaluate_error(y_pred_fair, y_test, grouprace_test)\n",
    "\n",
    "# Group labels\n",
    "group_labels = {0: 'All other races', 1: \"Black\", 2: \"White\"}\n",
    "\n",
    "# Convert numeric keys to labels\n",
    "group_acc = {group_labels.get(k, f\"Unknown {k}\"): v for k, v in group_acc.items()}\n",
    "\n",
    "# Convert to pandas Series\n",
    "group_acc_df = pd.Series(group_acc, name=\"Group Accuracy\")\n",
    "\n",
    "\n",
    "print(\"the accuracy is:\", accuracy)\n",
    "print(\"the group accuracy is:\\n\", group_acc_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is: 0.7582091840646003\n",
      "the group accuracy is:\n",
      " Black or African American alone    0.764558\n",
      "Unknown 0                          0.749660\n",
      "White alone                        0.734393\n",
      "Name: Group Accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Test for race\n",
    "predictions, accuracy, group_acc = evaluate_error(y_pred_fair, y_test, grouprace_test)\n",
    "\n",
    "# Group labels\n",
    "group_labels = {1: \"White alone\", 2: \"Black or African American alone\", 3: \"American Indian alone\", 4: \"Alaska Native alone\", 5: \"AI and AN tribes or AI or AN, not specified and no other races\", \n",
    "                6: \"Asian alone\", 7: \"Native Hawaiian and Other Pacific Islander alone\", 8: \"Some Other Race alone\", 9: \"Two or More Races\"}\n",
    "\n",
    "\n",
    "# Convert numeric keys to labels\n",
    "group_acc = {group_labels.get(k, f\"Unknown {k}\"): v for k, v in group_acc.items()}\n",
    "\n",
    "# Convert to pandas Series\n",
    "group_acc_df = pd.Series(group_acc, name=\"Group Accuracy\")\n",
    "\n",
    "\n",
    "print(\"the accuracy is:\", accuracy)\n",
    "print(\"the group accuracy is:\\n\", group_acc_df)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression model RAC1P fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
